#!/usr/bin/env python3
#
# vim: syntax=python
#
# Copyright 2018, Inc.
#
# The *M*etal-*A*rchives *Q*uery utility
#
# Author: Alexander Sack
#
# Description: 
#
# A command line tool to webscrape various "metalytics" from
# The Metal Archives website (http://www.metal-archives.com)
# and store the output in CSV format for offline use.
#
# There is no official API to actually query the site's backend
# database. Instead, this tool webscrapes the site via an internal
# JSON API embedded in search results.
#
# *** Permission has been granted by the webmaster HellBlazer to
# use this internal API for research purposes only. ***
#
# Special thanks to Peter Steele (RIP) and the boys in green.
import click
import csv
import datetime
import logging
import json
import progressbar
import requests
import string
import sys
import time
import urllib

from abc import abstractmethod
from fake_useragent import UserAgent
from bs4 import BeautifulSoup

# Allocate a useragent upfront which we will use to get
# 'User-Agent' strings do this tool creates normal
# browser access requests.
UA = UserAgent()

# Top level URL path component
MA_URL = 'http://www.metal-archives.com'

# AJAX reviews URL entrypoints relative to the top level
MA_REVIEWS_URL = '/review/ajax-list-browse/by/%s/selection/%s/json/1'

# AJAX band URL entrypoints relative to the top level
MA_BANDS_BY_LETTER_URL = '/browse/ajax-letter/l/%s/json/1'
MA_BANDS_BY_GENRE_URL = '/browse/ajax-genre/g/%s/json/1'
MA_BANDS_BY_COUNTRY_URL = '/browse/ajax-country/c/%s/json/1'

# Bands by letter entrypoint
MA_BANDS_BY_LETTER = '/browse/ajax-letter/l/'
MA_BAND_DISCO = '/band/discography/id/%d/tab/all'

# The following default headers were captures via tshark
# and seem to work without generating inexplicitable connection
# timeouts.
MA_HEADERS = {
        'User-Agent': str(UA.firefox),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Host': 'www.metal-archives.com'
}

# Default payload for MA's internal JSON interface
# Batch size is statically set to 500. 
MA_START = 0
MA_BATCHSIZE = 200
MA_PAYLOAD = {
        'sEcho': 1,
        'iColumns': 7,
        'iDisplayStart': MA_START,
        'iDisplayLength': MA_BATCHSIZE 
}

# Bands start with ASCII upper case letters or 'NBR'
MA_REVIEW_LETTERS = list(string.ascii_uppercase)

# Ratings are in 5% increments
MA_REVIEW_RATINGS = map(str, list(range(0, 101, 5)))

# MA reviews started in July 2002.
NOW = datetime.datetime.now()
MA_REVIEW_DATES_2002 = ["2002-%.2d" % x for x in range(7, 13)]
MA_REVIEW_DATES_2003_TO_NOW = ["%d-%.2d" % (x, y) for x in range(2003, NOW.year+1) for y in range(1, NOW.month+1)]      
MA_REVIEW_DATES = MA_REVIEW_DATES_2002 + MA_REVIEW_DATES_2003_TO_NOW  

# Valid band letters
MA_BAND_LETTERS = ['NBR'] + list(string.ascii_uppercase)
MA_BAND_COUNTRY_CODES = {
        'AF': 'Afganistan',
        'AX': 'Aland Islands',
        'AL': 'Albania',
        'DZ': 'Algeria',
        'AD': 'Andorra',
        'AO': 'Angola',
        'AR': 'Argentina',
        'AM': 'Armenia',
        'AW': 'Aruba',
        'AU': 'Australia',
        'AT': 'Austria',
        'AZ': 'Azerbaijan',
        'BR': 'Bahrain',
        'BD': 'Bangladesh',
        'BB': 'Barbados',
        'BE': 'Belgium',
        'BZ': 'Belize',
        'BO': 'Bolivia',
        'BA': 'Bosnia and Herzegovina',
        'BW': 'Botswana',
        'BR': 'Brazil',
        'BN': 'Brunei',
        'BG': 'Bulgaria',
        'KH': 'Cambodia',
        'CA': 'Canada',
        'CL': 'Chile',
        'CN': 'China',
        'CO': 'Columbia',
        'CR': 'Costa Rica',
        'HR': 'Croatia',
        'CU': 'Cuba',
        'CW': 'Curacao',
        'CY': 'Cyprus',
        'CZ': 'Czech Republic',
        'DK': 'Denmark',
        'DO': 'Dominican Republic',
        'EC': 'Ecuador',
        'EG': 'Egypt',
        'SV': 'El Salvador',
        'EE': 'Estonia',
        'ET': 'Ethiopia',
        'FO': 'Faroe Islands',
        'FI': 'Finland',
        'FR': 'France',
        'PF': 'French Polynesia',
        'GE': 'Georgia',
        'DE': 'Germany',
        'GI': 'Gibraltar',
        'GR': 'Greece',
        'GL': 'Greenland',
        'GU': 'Guam',
        'GT': 'Guatemala',
        'GG': 'Guernsey',
        'GY': 'Guyana',
        'HN': 'Honduras',
        'HK': 'Hong Kong',
        'HU': 'Hungary',
        'IS': 'Iceland',
        'IN': 'India',
        'ID': 'Indonesia',
        'XX': 'International',
        'IR': 'Iran',
        'IQ': 'Iraq',
        'IE': 'Ireland',
        'IM': 'Isle of Man',
        'IL': 'Israel',
        'IT': 'Italy',
        'JM': 'Jamaica',
        'JP': 'Japan',
        'JE': 'Jersey',
        'JO': 'Jordan',
        'KZ': 'Kazakhstan',
        'KE': 'Kenya',
        'KR': 'Korea',
        'KW': 'Kuwait',
        'KG': 'Kyrgyzstan',
        'LA': 'Laos',
        'LV': 'Latvia',
        'LB': 'Lebanon',
        'LY': 'Libya',
        'LI': 'Liechtenstein',
        'LT': 'Lithuania',
        'LU': 'Luxembourg',
        'MK': 'Macedonia (FYROM)', 
        'MG': 'Madagascar',
        'MY': 'Malaysia',
        'MV': 'Maldives',
        'MT': 'Malta',
        'MU': 'Mauritius',
        'MX': 'Mexico',
        'MD': 'Moldova',
        'MC': 'Monaco',
        'MN': 'Mongolia',
        'ME': 'Montenegro',
        'MA': 'Morocco',
        'MZ': 'Mozambique',
        'MM': 'Myanmar',
        'NA': 'Namibia',
        'NP': 'Nepal',
        'NL': 'Netherlands',
        'NC': 'New Caledonia', 
        'NZ': 'New Zealand',
        'NI': 'Nicaragua',
        'NO': 'Norway',
        'OM': 'Oman',
        'PK': 'Pakistan',
        'PA': 'Panama',
        'PY': 'Paraguay',
        'PE': 'Peru',
        'PH': 'Philippines',
        'PL': 'Poland',
        'PT': 'Portugal',
        'PR': 'Puerto Rico',
        'QA': 'Qatar',
        'RE': 'Reunion',
        'RO': 'Romania',
        'RU': 'Russia',
        'SM': 'San Marino',
        'SA': 'Saudi Arabia',
        'RS': 'Serbia',
        'SG': 'Singapore',
        'SK': 'Slovakia',
        'SI': 'Slovenia',
        'ZA': 'South Africa',
        'ES': 'Spain',
        'LK': 'Sri Lanka',
        'SR': 'Suriname',
        'SJ': 'Svalbard',
        'SE': 'Sweden',
        'CH': 'Switzerland', 
        'SY': 'Syria',
        'TW': 'Taiwan',
        'TJ': 'Tajikistan', 
        'TH': 'Thailand',
        'TT': 'Trinidad and Tobago', 
        'TN': 'Tunisia',
        'TR': 'Turkey',
        'TM': 'Turkmenistan',
        'UG': 'Uganda',
        'UA': 'Ukraine',
        'AE': 'United Arab Emirates',
        'GB': 'United Kingdom',
        'US': 'United States',
        'ZZ': 'Unknown',
        'UY': 'Uruguay',
        'UZ': 'Uzbekistan',
        'VE': 'Venezuela',
        'VN': 'Vietnam',
}

MA_BAND_GENRES = [
        'black',
        'death',
        'doom',
        'electronic',
        'avantgarde',
        'folk',
        'gothic',
        'grind',
        'groove',
        'heavy',
        'metalcore',
        'orchestral',
        'power',
        'prog',
        'speed',
        'thrash'
]

QUOTING_RULES = {
        'all': csv.QUOTE_ALL,
        'minimal': csv.QUOTE_MINIMAL,
        'nonnumeric': csv.QUOTE_NONNUMERIC,
        'none': csv.QUOTE_NONE,
}

# Fetch URL throttle tuneable (default is half a second)
THROTTLE = 0.5

# This is a bit overkill but we will construct a simple OOM.
# MA pages are backed by a URL. These pages in-turn represent
# instances of bands which record albums that users review.
class MAPage(object):
    def __init__(self, url):
        self.url = url

    def __str__(self):
        return self.url

    @abstractmethod
    def parse(self):
        """ Main method to parse a page into its constituent parts """
        raise NotImplemented

class MABand(MAPage):
    """ Metal-Archive Band page """

    def __init__(self, url):
        super().__init__(url)

        # MA's band id is the last component in the URL
        slashes = url.split('/')
        self.id = slashes[-1]
        self.name = urllib.parse.unquote(slashes[-2])
        self.origin = ""
        self.location = ""
        self.status = ""
        self.formedin = ""
        self.genre = ""
        self.themes = ""
        self.label = ""

    def parse(self):
        """ Parse a MA band page """

        r = fetch_url(self.url)
        r_soup = BeautifulSoup(r.content, 'lxml')

        # Try to find the HTML UTF-8 based band name
        # which should override the URL encoded one.
        h1 = r_soup.find('h1', {'class': 'band_name'})
        if not h1:
            self.name = h1.find_next().text.strip()

        for dt in r_soup.find_all('dt'):
            if dt.text == 'Country of origin:':
                self.origin = dt.find_next().text.strip()
            elif dt.text == 'Location:':
                self.location = dt.find_next().text.strip()
            elif dt.text == 'Status:':
                self.status = dt.find_next().text.strip()
            elif dt.text == 'Formed in:':
                self.formedin = dt.find_next().text.strip() 
            elif dt.text == 'Genre:':
                # Convert multiple entries separated by '|'
                genres = dt.find_next().text.strip().replace(',', '|')
                self.genre = ''.join(genres)
            elif dt.text == 'Lyrical themes:':
                # Convert multiple entries separated by '|'
                themes = dt.find_next().text.strip().replace(',', '|')
                self.themes = ''.join(themes)
            elif dt.text == 'Current label:':
                self.label = dt.find_next().text.strip()

    def to_list(self):
        """ Return fields as list """

        return [self.id, self.name, self.origin, self.location, self.status, self.formedin, self.genre, self.themes, self.label]

    def to_dict(self):
        """ Return fields as dict """

        d = {
                'bid': self.id,
                'name': self.name,
                'origin': self.origin,
                'location': self.location,
                'status': self.status,
                'formedin': self.formedin,
                'genre': self.genre,
                'themes': self.themes,
                'label': self.label,
        }

        return d

    @staticmethod
    def to_fields():
        """ Return field names as list """

        return ['bid', 'name', 'origin', 'location', 'status', 'formedin', 'genre', 'themes', 'label']

class MAReview(MAPage):
    """ Metal-Archive Review page """

    def __init__(self, url):
        super().__init__(url)

        slashes = url.split('/')
        self.id = slashes[-1]
        self.author = ""
        self.band = ""
        self.album = ""
        self.review = ""
        self.rating = ""
        self.date = ""

    def parse(self):
        """ Parse a MA review page """

        r = fetch_url(self.url)
        r_soup = BeautifulSoup(r.content, 'lxml')
        review = r_soup.find('div', {'class': 'reviewContent'})
        logger = logging.getLogger('maq')
        if review:
            self.review = review.text

    def to_list(self):
        """ Return fields as list """

        return self.band.to_list() + [self.album, self.author, self.review, self.rating, self.date]

    def to_dict(self):
        """ Return fields as dict """

        d = {
                'rid': self.id,
                'album': self.album,
                'author': self.author,
                'review': self.review,
                'rating': self.rating,
                'date': self.date,
        }
        d.update(self.band.to_dict())

        return d

    @staticmethod
    def to_fields():
        """ Return field names as list """

        return MABand.to_fields() + ['rid', 'album', 'author', 'review', 'rating', 'date']

def fetch_url(url, headers = MA_HEADERS, payload = MA_PAYLOAD):
    """ Connect to the MA and fetch the url """

    # Throttle request if asked
    if THROTTLE > 0:
        time.sleep(THROTTLE)
    r = requests.get(url, headers=headers, params=payload)
    r.raw.decode_content = True

    return r

def fetch_bands(by, criteria, start = MA_START):
    """ Fetch a list of bands in JSON format """

    # Sanity check letter
    if by == 'alpha':
        criteria = criteria.upper() if criteria != 'NBR' else criteria
        url = MA_URL + MA_BANDS_BY_LETTER_URL % criteria
    elif by == 'country':
        url = MA_URL + MA_BANDS_BY_COUNTRY_URL % criteria
    else:
        url = MA_URL + MA_BANDS_BY_GENRE_URL % criteria

    # Set how many records to return
    payload = MA_PAYLOAD
    payload['iDisplayStart'] = start


    # Try three times before giving up
    for _ in range(3):
        try:
            r = fetch_url(url, payload=payload)
            js = r.json()
        except Exception:
            js = None
            time.sleep(1) # backoff a little, be polite 
            continue
        break

    return js

def fetch_reviews(by, criteria, start = MA_START):
    """ Fetch a list of reviews in JSON format """

    # Sanity check letter
    if by == 'alpha':
        criteria = criteria.upper() if criteria != 'NBR' else criteria
    url = MA_URL + MA_REVIEWS_URL % (by, criteria)

    # Set how many records to return
    payload = MA_PAYLOAD
    payload['iDisplayStart'] = start
    
    # Try three times before giving up
    for _ in range(3):
        try:
            r = fetch_url(url, payload=payload)
            js = r.json()
        except Exception:
            js = None
            time.sleep(1) # backoff a little, be polite 
            continue
        break

    return js

class MAQ(object):
    """ Command line interface """

    def __init__(self, csvfile = None, csvdelimiter = ',', header = True, \
            quoting = csv.QUOTE_ALL, verbose = False):

        self.csvfile = csvfile
        self.csvdelimiter = csvdelimiter
        self.header = header
        self.csvwriter = None
        self.quoting = quoting
        self.verbose = verbose

    def write_header(self, fields = None):
        """ Optionally write CSV header """

        # Walk through each review by letter
        if self.header:
            if self.csvfile:
                self.csvwriter = csv.DictWriter(self.csvfile, delimiter = self.csvdelimiter, \
                        fieldnames = fields, quoting = self.quoting)
                self.csvwriter.writeheader()
            else:
                click.echo(self.csvdelimiter.join(fields))

        # We only do this once
        self.header = False

    def progress_bar(self, maxval):
        """ Setup a basic progress bar """

        self.bar = progressbar.ProgressBar(maxval=maxval, \
                widgets = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])
        self.bar.start()

    def query(self, qtype, by, \
            letters = MA_REVIEW_LETTERS, ratings = MA_REVIEW_RATINGS, \
            dates = MA_REVIEW_DATES, countries = MA_BAND_COUNTRY_CODES, \
            genres = MA_BAND_GENRES, records = -1):
        """ Query MA """

        logger.info("Query %s by %s"% (qtype, by))

        if by == 'alpha':
            criteria = letters
        elif by == 'rating':
            criteria = ratings
        elif by == 'country':
            criteria = countries
        elif by == 'genre':
            criteria = genres
        else:
            criteria = dates

        # First find the total number of records we plan to fetch
        # We need to do this in two passes unfortunately.
        trs = 0
        for c in criteria:
            if qtype == 'reviews':
                js = fetch_reviews(by, criteria = c)
            else:
                js = fetch_bands(by, criteria = c)
            itrs = int(js['iTotalRecords'])
            logger.info("Found total of %5d records for %s criteria %s..." % (itrs, by, c))
            trs += itrs

        # If asked to fetch only N number of records, honor it.
        if records != -1: 
            itrs = min(records, itrs)
        logger.info("Found a total of %5d records for all %s criteria to retrieve..." % (itrs, by))

        for c in criteria:
            if itrs > 0:
                logger.info("Processing reviews with the %s criteria %s..." % (by, c))
                js = fetch_reviews(by, criteria = c)
                trs = min(int(js['iTotalRecords']), itrs)
                if self.verbose:
                    self.progress_bar(trs)
                batches = trs//MA_BATCHSIZE
                batches = batches + 1 if trs % MA_BATCHSIZE != 0 else batches
                logger.info("Retrieving %d total records (batches = %d, batchsize = %d)..." % \
                        (trs, batches, MA_BATCHSIZE))
                nrecords = 0
                for b in range(batches):
                    entries = []
                    if trs > 0:
                        logger.info("Fetching batch %d..." % b)
                        if qtype == 'reviews':
                            js = fetch_reviews(by, criteria = c, start = b * MA_BATCHSIZE)
                        else:
                            js = fetch_bands(by, criteria = c, start = b * MA_BATCHSIZE)
                        if js:
                            aaData = js['aaData']
                            logger.info("%d records in this batch..." % len(aaData))
                            for aa in aaData:
                                if qtype == 'reviews':
                                    # Each review entry ('aa') consists of a:
                                    #   - band name
                                    #   - review url
                                    #   - band url
                                    #   - album url
                                    #   - rating percentage
                                    #   - author url
                                    #   - date of review
                                    if len(aa) == 7:
                                        ahref = BeautifulSoup(aa[1], "lxml")
                                        mar = MAReview(ahref.find('a').get('href'))
                                        mar.parse()
                                        ahref = BeautifulSoup(aa[2], "lxml")
                                        mar.band = MABand(ahref.find('a').get('href'))
                                        mar.band.parse()
                                        ahref = BeautifulSoup(aa[3], "lxml")
                                        mar.album = ahref.text
                                        mar.rating = aa[4]
                                        ahref = BeautifulSoup(aa[5], "lxml")
                                        mar.author = ahref.text
                                        mar.date = aa[6]
                                        entries.append(mar)
                                    else:
                                        logger.warn("Malformed review entry: %s..." % aa)
                                else:
                                    # Each band entry ('aa') consists of a:
                                    #   - band url
                                    #   - country of origin
                                    #   - genre
                                    #   - status
                                    if len(aa) == 4:
                                        ahref = BeautifulSoup(aa[0], "lxml")
                                        mab = MABand(ahref.find('a').get('href'))
                                        mab.parse()
                                        entries.append(mab)
                                    else:
                                        logger.warn("Malformed band entry: %s..." % aa)
                                nrecords += 1
                                if self.verbose:
                                    self.bar.update(nrecords)
                                if nrecords == trs:
                                    break
                        else:
                            logger.warn("Failed to get json for batch %d..." % b)

                    # Write out our batch group now
                    itrs -= trs
                    fields = MAReview.to_fields() if qtype == 'review' else MABand.to_fields()
                    self.write_header(fields = fields)
                    for entry in entries:
                        if self.csvfile:
                            self.csvwriter.writerow(entry.to_dict())
                        else:
                            click.echo(self.csvdelimiter.join(entry.to_list()))
                    logger.info("Processed %d records..." % len(entries))
                if self.verbose:
                    self.bar.finish()
        return 0

def setup_logging(verbose = False):
     """ Setup the global logger """

     global logger

     level = logging.INFO if verbose else logging.ERROR
     logging.basicConfig(level = level, format = "%(asctime)s %(levelname)s: %(message)s")
     logger = logging.getLogger("maq")

@click.group()
@click.option('--csvfile', '-c', type = click.File('w', encoding = 'utf-8'), default = None, help = 'CSV format')
@click.option('--delimiter', '-d', type = click.STRING, default = ',', help = 'CSV delimeter')
@click.option('--header/--noheader', default = True, help = 'Write header')
@click.option('--quoting', '-q', type = click.Choice(QUOTING_RULES.keys()), default = 'all', help= 'CSV quoting behavior')
@click.option('--throttle', '-t', type = click.FLOAT, default = THROTTLE, help = 'Throttle requests (seconds)')
@click.option('--verbose', '-v', is_flag = True, default = False, help = 'Verbose mode')
@click.pass_context
def cli(ctx, csvfile, delimiter, header, quoting, throttle, verbose):
    """ Metal-Archives Query """
    global THROTTLE

    # Instastiate our logger for the our whole run.
    setup_logging(verbose)

    # Set any globals
    THROTTLE = throttle
    if THROTTLE > 0:
        logger.info("All requests will be throttled by %.2f second(s)..." % THROTTLE)

    # Build our command line application that will do
    # all the grunt work.
    ctx.obj = MAQ(csvfile = csvfile, csvdelimiter = delimiter, \
            header = header, quoting = QUOTING_RULES[quoting], verbose = verbose)

@cli.command()
@click.option('--by', '-b', type = click.Choice(['alpha', 'date', 'rating']), default = 'alpha', help = 'Query by')
@click.option('--date', '-d', type = click.STRING, default = None, help = 'Year-Date [YYYY-MM]')
@click.option('--letter', '-l', type = click.STRING, default = None, help = 'First letter of band name')
@click.option('--number', '-n', type = click.INT, default = -1, help = 'Number of records to return')
@click.option('--rating', '-r', type = click.Choice(map(str, list(range(0, 101, 5)))), default = None, help = 'Review rating')
@click.pass_obj
def reviews(maq, by, date, letter, number, rating):
    """ Query reviews """

    # Query every letter by default
    if by == 'alpha':
        letter = MA_REVIEW_LETTERS if not letter else [letter.upper()]
    elif by == 'rating':
        rating = MA_REVIEW_RATINGS if not rating else [rating]
    else:
        date = MA_REVIEW_DATES if not date else [date]

    return maq.query('reviews', by, letters = letter, ratings = rating, dates = date, records = number)

@cli.command()
@click.option('--by', '-b', type = click.Choice(['alpha', 'country', 'genre']), default = 'alpha', help = 'Query by')
@click.option('--country', '-c', type = click.Choice(MA_BAND_COUNTRY_CODES.keys()), default = None, help = 'Band country code')
@click.option('--genre', '-g', type = click.Choice(MA_BAND_GENRES), default = None, help = 'Band genre')
@click.option('--letter', '-l', type = click.STRING, default = None, help = 'First letter of band name')
@click.option('--listcountries', flag_value = True, help = 'List country code -> country')
@click.option('--number', '-n', type = click.INT, default = -1, help = 'Number of records to return')
@click.pass_obj
def bands(maq, by, country, genre, letter, listcountries, number):
    """ Query bands """

    if listcountries:
        for n,v in sorted(MA_BAND_COUNTRY_CODES.items()):
            click.echo("%s -> %s" % (n,v))
        return 0

    # Query every letter by default
    if by == 'alpha':
        letter = MA_REVIEW_LETTERS if not letter else [letter.upper()]
    elif by == 'country':
        country = MA_BAND_COUNTRY_CODES if not country else [country.upper()]
    else:
        genre = MA_BAND_GENRES if not genre else [genre]

    return maq.query('bands', by, letters = letter, countries = country, genres = genre, records = number)

# Main main MAIN
if __name__ == '__main__':
    sys.exit(cli())
